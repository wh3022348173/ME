# pyspark

PySpark的编程模型

•数据输入：通过SparkContext完成数据读取

•数据计算：读取到的数据转换为RDD对象，调用RDD的成员方法完成计算

•数据输出：调用RDD的数据输出相关成员方法，将结果输出到list、元组、字典、文本文件、数据库等

### **RDD**对象

PySpark针对数据的处理，都是以RDD对象作为载体

•数据存储在RDD内

•各类数据的计算方法，也都是RDD的成员方法

•RDD的数据计算方法，返回值依旧是RDD对象

### PySpark的编程模型

•准备数据到RDD -> RDD迭代计算 -> RDD导出为list、文本文件等

•即：源数据 -> RDD -> 结果数据